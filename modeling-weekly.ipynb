{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, spearmanr\n",
    "import shap\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, LeavePGroupsOut, LeaveOneGroupOut, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "seed = 69\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c79e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all-features-imputed-v2.csv')\n",
    "\n",
    "display(data)\n",
    "display(data.columns.to_list())\n",
    "\n",
    "\n",
    "acceleration    = data.filter(like='acceleration').columns.tolist()\n",
    "heartrate       = data.filter(like='heartrate').filter(regex='^(?!.*sleep)').columns.tolist()\n",
    "motion          = data.filter(like='motion').columns.tolist()\n",
    "position        = data.filter(like='position').columns.tolist()\n",
    "sleep           = data.filter(like='sleep').columns.tolist()\n",
    "step            = data.filter(like='step').columns.tolist()\n",
    "demographics    = ['sex', 'age']\n",
    "\n",
    "\n",
    "\n",
    "display(acceleration)\n",
    "display(heartrate)\n",
    "display(motion)\n",
    "display(position)\n",
    "display(sleep)\n",
    "display(step)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = acceleration + heartrate + motion + position + sleep + step\n",
    "sensor = data[modalities]\n",
    "\n",
    "sis = data['sis']\n",
    "participant = data['participant']\n",
    "\n",
    "x = np.array(sensor)\n",
    "y = np.array(sis)\n",
    "p = np.array(participant)\n",
    "\n",
    "display(x.shape, y.shape, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38574f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TRUES = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "SHAP = []\n",
    "X_TEST = []\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "    \n",
    "    print(f\"Fold {fold}: train={len(train_idx)} test={len(test_idx)}\")\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    x_train = normalizer.fit_transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        depth=3,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train, eval_set=(x_train, y_train), use_best_model=True, early_stopping_rounds=100)\n",
    "    y_preds = model.predict(x_test)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "    SHAP.append(shap_values)\n",
    "    X_TEST.append(x_test)\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': modalities,\n",
    "    'mean_abs_shap': np.abs(np.vstack(SHAP)).mean(axis=0).round(4)\n",
    "}).sort_values(by='mean_abs_shap', ascending=False)\n",
    "# display(shap_df)\n",
    "shap.summary_plot(np.vstack(SHAP), pd.DataFrame(np.vstack(X_TEST), columns=modalities), max_display=24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Select the first num_features features based on SHAP importance + demographics\n",
    "num_features = 64\n",
    "x = np.array(data[\n",
    "    shap_df['feature'].iloc[:num_features].to_list()\n",
    "    # + demographics\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa881bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby(['clinical-timestamp', 'participant'], sort=False)\n",
    "\n",
    "most_common_features_16 = ['acceleration-mean', 'heartrate-std', 'position-count', 'position-mean', 'position-max', 'position-duration', 'position-travelled-distance', 'sleep-deep', 'motion-mean', 'sleep-heartrate-mean', 'motion-count', 'motion-max', 'sleep-rem', 'acceleration-movement-events-24h', 'sleep-light', 'acceleration-movement-events-18to24']\n",
    "most_common_features_24 = ['acceleration-mean', 'acceleration-movement-events-12to18', 'heartrate-std', 'motion-count', 'motion-mean', 'position-count', 'position-mean', 'position-max', 'position-duration', 'position-travelled-distance', 'sleep-deep', 'sleep-light', 'sleep-rem', 'sleep-heartrate-mean', 'acceleration-minutes-with-data', 'acceleration-movement-events-00to06', 'acceleration-movement-events-18to24', 'motion-max', 'sleep-snoring-duration', 'sleep-heartrate-min', 'step-mean', 'acceleration-movement-events-24h', 'motion-max-timestamp', 'heartrate-mean']\n",
    "\n",
    "\n",
    "\n",
    "y = []\n",
    "p = []\n",
    "x = []\n",
    "\n",
    "num_features = 16\n",
    "\n",
    "for name, group in grouped:\n",
    "\n",
    "    sis = group['sis'].iloc[0]\n",
    "    participant = group['participant'].iloc[0].item()\n",
    "    group = group[\n",
    "        # shap_df['feature'].iloc[:num_features].to_list()\n",
    "        most_common_features_24\n",
    "        # + demographics\n",
    "        ]\n",
    "\n",
    "    # weekly\n",
    "    y.append(sis)\n",
    "    p.append(participant)\n",
    "    x.append(group.iloc[:7])\n",
    "    \n",
    "    y.append(sis)\n",
    "    p.append(participant)\n",
    "    x.append(group.iloc[7:])\n",
    "\n",
    "    # biweekly\n",
    "    # y.append(sis)\n",
    "    # p.append(participant)\n",
    "    # x.append(group)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "p = np.array(p)\n",
    "\n",
    "display(x.shape, y.shape, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302acbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROCKET -- CatBoost\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "# cv = LeaveOneOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "# cv = LeaveOneGroupOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x, y, groups=p), start=1):\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "    print(f\"Fold {fold}: train={len(train_idx)} test={len(test_idx)}\")\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "    # Standardaizetion-Normalization\n",
    "    x_train_2d = x_train.reshape(-1, x_train.shape[2])\n",
    "    x_test_2d = x_test.reshape(-1, x_test.shape[2])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train_2d)\n",
    "    x_test_scaled = scaler.transform(x_test_2d)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    x_train_normalized = normalizer.fit_transform(x_train_scaled)\n",
    "    x_test_normalized = normalizer.transform(x_test_scaled)\n",
    "\n",
    "    x_train = x_train_normalized.reshape(x_train.shape[0], x_train.shape[1], -1)\n",
    "    x_test = x_test_normalized.reshape(x_test.shape[0], x_test.shape[1], -1)\n",
    "\n",
    "\n",
    "    # ----- ROCKET - Catboost\n",
    "    rocket = Rocket(num_kernels=1_000)\n",
    "    rocket.fit(x_train)\n",
    "    x_train_transformed = rocket.transform(x_train)\n",
    "    x_test_transformed = rocket.transform(x_test)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=.1,\n",
    "        depth=3,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    model.fit(x_train_transformed, y_train,\n",
    "              eval_set=(x_train_transformed, y_train),\n",
    "            #   eval_set=(x_test_transformed, y_test),              \n",
    "              use_best_model=True, early_stopping_rounds=100)\n",
    "    \n",
    "    y_preds = model.predict(x_test_transformed)\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "mae = mean_absolute_error(Y_TRUES, Y_PREDS)\n",
    "mse = mean_squared_error(Y_TRUES, Y_PREDS)\n",
    "r2 = r2_score(Y_TRUES, Y_PREDS)\n",
    "corr, _ = spearmanr(Y_TRUES, Y_PREDS)\n",
    "\n",
    "results = {\n",
    "    'mae': f\"{mae:.4f}\",\n",
    "    'mse': f\"{mse:.4f}\",\n",
    "    'r2_score': f\"{r2:.4f}\",\n",
    "    'correlation': f\"{corr:.4f}\"\n",
    "}\n",
    "\n",
    "results = pd.DataFrame([results])\n",
    "display(results.style.hide(axis='index'))\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=range(len(Y_TRUES)), y=Y_TRUES, label='Ground-truth', color='blue', alpha=0.4, s=60)\n",
    "sns.scatterplot(x=range(len(Y_PREDS)), y=Y_PREDS, label='Prediction', color='red', alpha=0.4, s=60)\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title(f\"MAE = {mae:.4f}, MSE = {mse:.4f}, R² = {r2:.4f}, Correlation = {corr:.4f}\")\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words - CatBoost\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "\n",
    "def histogram(inputs, num_bins):\n",
    "    counts = np.zeros(num_bins)\n",
    "    for input in inputs:\n",
    "        for i in range(num_bins):\n",
    "            if input == i:\n",
    "                counts[i] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "# cv = LeaveOneOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "# cv = LeaveOneGroupOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x, y, groups=p), start=1):\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "    print(f\"Fold {fold}: train={len(train_idx)} test={len(test_idx)}\")\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "    # Standardaizetion-Normalization\n",
    "    x_train_2d = x_train.reshape(-1, x_train.shape[2])\n",
    "    x_test_2d = x_test.reshape(-1, x_test.shape[2])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train_2d)\n",
    "    x_test_scaled = scaler.transform(x_test_2d)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    x_train_normalized = normalizer.fit_transform(x_train_scaled)\n",
    "    x_test_normalized = normalizer.transform(x_test_scaled)\n",
    "\n",
    "    x_train = x_train_normalized.reshape(x_train.shape[0], x_train.shape[1], -1)\n",
    "    x_test = x_test_normalized.reshape(x_test.shape[0], x_test.shape[1], -1)\n",
    "\n",
    "\n",
    "    # ----- Bag-of-Words - CatBoost\n",
    "    n_clusters = 16\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=seed).fit(x_train_normalized)\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    hist_train = []\n",
    "    for fs in x_train:\n",
    "        indices = []\n",
    "        for f in fs:\n",
    "            indices.append(np.argmin([mse(f, center) for center in centers]))\n",
    "        h = histogram(indices, centers.shape[0])\n",
    "        hist_train.append(h)\n",
    "    hist_train = np.array(hist_train)\n",
    "\n",
    "    hist_test = []\n",
    "    for fs in x_test:\n",
    "        indices = []\n",
    "        for f in fs:\n",
    "            indices.append(np.argmin([mse(f, center) for center in centers]))\n",
    "        h = histogram(indices, centers.shape[0])\n",
    "        hist_test.append(h)\n",
    "    hist_test = np.array(hist_test)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=.1,\n",
    "        depth=3,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    model.fit(hist_train, y_train,\n",
    "              eval_set=(hist_train, y_train),\n",
    "            #   eval_set=(hist_test, y_test),              \n",
    "              use_best_model=True, early_stopping_rounds=100)\n",
    "    \n",
    "    y_preds = model.predict(hist_test)\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "mae = mean_absolute_error(Y_TRUES, Y_PREDS)\n",
    "MSE = mean_squared_error(Y_TRUES, Y_PREDS)\n",
    "r2 = r2_score(Y_TRUES, Y_PREDS)\n",
    "corr, _ = spearmanr(Y_TRUES, Y_PREDS)\n",
    "\n",
    "results = {\n",
    "    'mae': f\"{mae:.4f}\",\n",
    "    'mse': f\"{MSE:.4f}\",\n",
    "    'r2_score': f\"{r2:.4f}\",\n",
    "    'correlation': f\"{corr:.4f}\"\n",
    "}\n",
    "\n",
    "results = pd.DataFrame([results])\n",
    "display(results.style.hide(axis='index'))\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=range(len(Y_TRUES)), y=Y_TRUES, label='Ground-truth', color='blue', alpha=0.4, s=60)\n",
    "sns.scatterplot(x=range(len(Y_PREDS)), y=Y_PREDS, label='Prediction', color='red', alpha=0.4, s=60)\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title(f\"MAE = {mae:.4f}, MSE = {MSE:.4f}, R² = {r2:.4f}, Correlation = {corr:.4f}\")\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87839ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words - TabPFN\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "\n",
    "def histogram(inputs, num_bins):\n",
    "    counts = np.zeros(num_bins)\n",
    "    for input in inputs:\n",
    "        for i in range(num_bins):\n",
    "            if input == i:\n",
    "                counts[i] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "# cv = LeaveOneOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "# cv = LeaveOneGroupOut()\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x, y, groups=p), start=1):\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "\n",
    "    print(f\"Fold {fold}: train={len(train_idx)} test={len(test_idx)}\")\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "    # Standardaizetion-Normalization\n",
    "    x_train_2d = x_train.reshape(-1, x_train.shape[2])\n",
    "    x_test_2d = x_test.reshape(-1, x_test.shape[2])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train_2d)\n",
    "    x_test_scaled = scaler.transform(x_test_2d)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    x_train_normalized = normalizer.fit_transform(x_train_scaled)\n",
    "    x_test_normalized = normalizer.transform(x_test_scaled)\n",
    "\n",
    "    x_train = x_train_normalized.reshape(x_train.shape[0], x_train.shape[1], -1)\n",
    "    x_test = x_test_normalized.reshape(x_test.shape[0], x_test.shape[1], -1)\n",
    "\n",
    "\n",
    "    # ----- Bag-of-Words - TabPFN\n",
    "    n_clusters = 16\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=seed).fit(x_train_normalized)\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    hist_train = []\n",
    "    for fs in x_train:\n",
    "        indices = []\n",
    "        for f in fs:\n",
    "            indices.append(np.argmin([mse(f, center) for center in centers]))\n",
    "        h = histogram(indices, centers.shape[0])\n",
    "        hist_train.append(h)\n",
    "    hist_train = np.array(hist_train)\n",
    "\n",
    "    hist_test = []\n",
    "    for fs in x_test:\n",
    "        indices = []\n",
    "        for f in fs:\n",
    "            indices.append(np.argmin([mse(f, center) for center in centers]))\n",
    "        h = histogram(indices, centers.shape[0])\n",
    "        hist_test.append(h)\n",
    "    hist_test = np.array(hist_test)\n",
    "\n",
    "\n",
    "    model = TabPFNRegressor(\n",
    "        device='cuda',\n",
    "        random_state=seed,\n",
    "        n_estimators = 4,\n",
    "        ignore_pretraining_limits=True)\n",
    "    model.fit(hist_train, y_train)\n",
    "    y_probs = model.predict(hist_test)\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "mae = mean_absolute_error(Y_TRUES, Y_PREDS)\n",
    "MSE = mean_squared_error(Y_TRUES, Y_PREDS)\n",
    "r2 = r2_score(Y_TRUES, Y_PREDS)\n",
    "corr, _ = spearmanr(Y_TRUES, Y_PREDS)\n",
    "\n",
    "results = {\n",
    "    'mae': f\"{mae:.4f}\",\n",
    "    'mse': f\"{MSE:.4f}\",\n",
    "    'r2_score': f\"{r2:.4f}\",\n",
    "    'correlation': f\"{corr:.4f}\"\n",
    "}\n",
    "\n",
    "results = pd.DataFrame([results])\n",
    "display(results.style.hide(axis='index'))\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=range(len(Y_TRUES)), y=Y_TRUES, label='Ground-truth', color='blue', alpha=0.4, s=60)\n",
    "sns.scatterplot(x=range(len(Y_PREDS)), y=Y_PREDS, label='Prediction', color='red', alpha=0.4, s=60)\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title(f\"MAE = {mae:.4f}, MSE = {MSE:.4f}, R² = {r2:.4f}, Correlation = {corr:.4f}\")\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ali-env-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
